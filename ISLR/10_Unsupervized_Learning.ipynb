{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまで訓練データを用いて予測モデルを作成し，テストデータや予測用データに予測モデルを適応させる「教師あり学習」について学習してきた。\n",
    "\n",
    "この章では，予測ではなく解析のための「教師なし学習」について学習していく。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Challenge of Unsupervised Learning\n",
    "\n",
    "教師なし学習はよく「探索的データ分析」としてふるまう。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Principal Components Analysis（主成分分析）\n",
    "\n",
    "主成分回帰は6.3.1章で紹介している。主成分回帰では予測子として主成分を使って回帰モデルに適応させる。\n",
    "\n",
    "主成分分析では主成分を求める過程を言及する。\n",
    "\n",
    "### 1. What Are Principal Components?\n",
    "\n",
    "第一主成分を標準化された線形結合で示すと，次のようになる。\n",
    "$$\n",
    "Z_1 = \\phi_{11}X_1 + \\phi_{21}X_2 + \\dots + \\phi_{p1}X_p \\tag{10.1}\n",
    "$$\n",
    "第一主成分は最も分散が大きいものである。標準化することによって，$\\sum_{j=1}^p\\phi_{j1}^2=1$となる。この$\\phi_1 = (\\phi_{11}\\ \\phi_{21}\\ \\dots\\ \\phi_{p1})^T$は主成分固有ベクトルとなる。\n",
    "\n",
    "第二主成分は第一主成分と無相関な成分であり，第二主成分の固有ベクトルは第一主成分の固有ベクトルに直交するようになる。変数が2つの場合は，第二主成分は第一主成分が決定すると同時に一意に決まる。\n",
    "\n",
    "変数が2より多い場合，第二主成分は第一主成分の固有ベクトルに対して直交なベクトルを持つ，第一主成分以外で最も分散が大きい成分となる。\n",
    "\n",
    "さらに，第三主成分は，第一・第二主成分のベクトルの双方と直交した固有ベクトルを持ち，第一・第二主成分以外で最も分散が大きい成分となる。\n",
    "\n",
    "これをひたすら続けていき，変数の数の分だけ主成分と固有ベクトルを生成することができる。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
